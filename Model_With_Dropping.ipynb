{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475012c6",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a0bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile as wav\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "from pydub import AudioSegment\n",
    "import matplotlib\n",
    "from pydub.playback import play\n",
    "from collections import deque "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05668a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer:\n",
    "\n",
    "    def __init__(self, file_path,source='Sound_Files/'):\n",
    "        self.audio = AudioSegment.from_wav(source+file_path)\n",
    "        self.file_name = file_path\n",
    "        self.SAMPLE_RATE, self.data = wav.read(source+file_path)\n",
    "        self.DURATION = len(self.audio)/1000\n",
    "        self.xf, self.stft_out = None, None\n",
    "\n",
    "    def play_file(self):\n",
    "        return self.audio\n",
    "\n",
    "    def split_audio(self, k=1):\n",
    "\n",
    "        s = np.round(len(self.audio)/k)\n",
    "        return [self.audio[i*s:(i+1)*s] for i in range(k)]\n",
    "        # return np.split(self.audio,k)\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data\n",
    "\n",
    "    def fft(self):\n",
    "        clip_duration = 0.5\n",
    "        end_index = int(np.rint(self.data.shape[0] * (clip_duration / self.DURATION))) # 1st 500 ms of audio\n",
    "        clip_data = self.data[:end_index]\n",
    "\n",
    "        duration = clip_duration\n",
    "        # N = self.SAMPLE_RATE * self.DURATION\n",
    "        N = int(self.SAMPLE_RATE * duration)\n",
    "\n",
    "        self.xf = fftfreq(N, 1 / self.SAMPLE_RATE)\n",
    "        return self.xf,fft(clip_data)\n",
    "\n",
    "    def plot(self, l, r,save_path,k=1,lim=1,rows=1,my_top=0.9):\n",
    "        cols = int(k/rows)\n",
    "        fig, axs = plt.subplots(rows,cols,figsize=(20,3*rows))\n",
    "        cur_data, cur_out = self.stft(k)\n",
    "        fig.suptitle('File ' + self.file_name)\n",
    "        fig.subplots_adjust(top=my_top)\n",
    "        if lim > len(cur_out):\n",
    "            lim = len(cur_out)\n",
    "        cur_out = cur_out[:lim]\n",
    "        for i in range(lim):\n",
    "            x = int(i/cols)\n",
    "            y = i%cols\n",
    "            if k == 1:\n",
    "                cur_ax = axs\n",
    "            else:\n",
    "                if rows == 1:\n",
    "                    cur_ax = axs[y]\n",
    "                else:\n",
    "                    cur_ax = axs[x,y]\n",
    "            cur_ax.title.set_text('Split ' + str(i+1))\n",
    "            cur_ax.plot(cur_data,np.abs(cur_out[i]))\n",
    "\n",
    "            cur_ax.set_ylim(0,2e7)\n",
    "            cur_ax.set_xlim(l,r)\n",
    "        if k==1:\n",
    "            axs.set(xlabel='Frequencies', ylabel='Amplitudes')\n",
    "        else:\n",
    "            for ax in axs.flat:\n",
    "                ax.set(xlabel='Frequencies', ylabel='Amplitudes')\n",
    "\n",
    "            # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "            for ax in axs.flat:\n",
    "                ax.label_outer()\n",
    "\n",
    "        fig.subplots_adjust(hspace=.2)\n",
    "        plt.savefig('STFT_Graphs/' + save_path)\n",
    "\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "db4a806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FREQS = 7\n",
    "\n",
    "def filter_signal(old_x,old_y):\n",
    "    # Filter frequencies 0-5000\n",
    "    l = -1\n",
    "    r = -1\n",
    "    for i in range(len(old_x)):\n",
    "        if old_x[i] >= 0 and l == -1:\n",
    "            l = i\n",
    "        if old_x[i] > 5000 and r == -1:\n",
    "            r = i\n",
    "    x = old_x[l:r]\n",
    "    y = old_y[l:r]\n",
    "    \n",
    "    # Find local maxima\n",
    "    local_maxima_x = []\n",
    "    local_maxima_y = []\n",
    "    HALFWAY_NOTE_DOWN_RATIO = 2 ** (1/24) # sqrt of the ratio of the freq of any note to one note lower\n",
    "    queue = deque([0]) \n",
    "    maxima_flags = [False] * x.shape[0]\n",
    "    cur_index = 1\n",
    "    while cur_index < x.shape[0]:\n",
    "        if y[cur_index] >= y[queue[0]]:\n",
    "            # clear queue only if new potential maxima found\n",
    "            queue.clear()\n",
    "            maxima_flags[cur_index] = True        \n",
    "        queue.append(cur_index)\n",
    "            \n",
    "        # if value in queue moves out of the range, check if maxima and then remove\n",
    "        if queue[0] <= cur_index / HALFWAY_NOTE_DOWN_RATIO:\n",
    "            if maxima_flags[queue[0]]:\n",
    "                local_maxima_x.append(x[queue[0]])\n",
    "                local_maxima_y.append(y[queue[0]])\n",
    "            queue.popleft()\n",
    "        cur_index += 1\n",
    "    \n",
    "    # pick out highest amplitude frequencies\n",
    "    stacked_data = np.stack((local_maxima_x,local_maxima_y))\n",
    "    sorted_stacked_data = stacked_data[:,np.flip(stacked_data[1,:].argsort())]\n",
    "    extracted_data = sorted_stacked_data[:,:NUM_FREQS]\n",
    "    data_resorted_by_freq = extracted_data[:,extracted_data[0,:].argsort()]\n",
    "    \n",
    "    return  data_resorted_by_freq[0], data_resorted_by_freq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "60d6b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "ebc65ecf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4A3.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4A4.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4B3.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4B4.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4C5.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4D4.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4D5.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4E4.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4E5.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4F4.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4F5.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4G4.wav', 'Sound_Files/C_Fourth_Octave_Final_Piano_1\\\\C4G5.wav']\n",
      "[[ 218.  260.  438.  520.  656.  782. 1044.]\n",
      " [ 260.  438.  520.  782.  876. 1044. 1838.]\n",
      " [ 246.  260.  492.  520.  738.  782.  984.]\n",
      " [ 260.  492.  522.  782.  986. 1044. 1838.]\n",
      " [ 260.  520.  566.  782. 1044. 1570. 1838.]\n",
      " [ 260.  292.  520.  586.  782. 1044. 1838.]\n",
      " [ 260.  520.  586.  782. 1044. 1174. 1838.]\n",
      " [ 260.  328.  520.  656.  782.  986. 1044.]\n",
      " [ 156.  260.  490.  520.  658.  748.  782.]\n",
      " [ 260.  348.  520.  696.  782. 1044. 1838.]\n",
      " [ 260.  520.  698.  782. 1044. 1306. 1838.]\n",
      " [  82.  260.  390.  520.  782. 1044. 1838.]\n",
      " [ 260.  520.  782. 1044. 1306. 1566. 1838.]]\n",
      "[{'A3', 'C4'}, {'A4', 'C4'}, {'C4', 'B3'}, {'C4', 'B4'}, {'C4', 'C5'}, {'C4', 'D4'}, {'C4', 'D5'}, {'E4', 'C4'}, {'C4', 'E5'}, {'C4', 'F4'}, {'F5', 'C4'}, {'C4', 'G4'}, {'G5', 'C4'}]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(glob.glob(\"Sound_Files/C_Fourth_Octave_Final_Piano_1/*\"))\n",
    "\n",
    "data = []\n",
    "label_strings = []\n",
    "\n",
    "for sound_file in glob.glob(\"Sound_Files/C_Fourth_Octave_Final_Piano_1/*\"):\n",
    "    filename = sound_file[12:]\n",
    "    test = Analyzer(filename)\n",
    "\n",
    "    x_fft, fft_arr = test.fft()\n",
    "    #plt.plot(x_fft,np.abs(fft_arr))\n",
    "    #plt.xlim(0,5000)\n",
    "    #plt.show()\n",
    "\n",
    "    freqs, amplitudes = filter_signal(x_fft,np.abs(fft_arr))\n",
    "    data.append(freqs)\n",
    "    #print(freqs)\n",
    "\n",
    "    #plt.scatter(freqs,amplitudes)\n",
    "    #plt.show()\n",
    "    \n",
    "    labels = set([filename[-8:-6], filename[-6:-4]])\n",
    "    label_strings.append(labels)\n",
    "#\n",
    "data = np.array(data)\n",
    "print(data)\n",
    "print(label_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d901ea07",
   "metadata": {},
   "source": [
    "# Model and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "88c3e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "e97a6f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns z as an array in base 3\n",
    "def compute_v(z):\n",
    "    v = np.base_repr(z,base=3).zfill(NUM_FREQS)\n",
    "    return np.array([int(j) for j in list(v)])\n",
    "\n",
    "# returns corresponding disallowed latent\n",
    "def compute_disallowed_z(z):\n",
    "    v = compute_v(z)\n",
    "    disallowed_latent = 0\n",
    "    base_component = 3 ** NUM_FREQS\n",
    "    for i in range(NUM_FREQS):\n",
    "        base_component /= 3\n",
    "        if v[i] == 2:\n",
    "            disallowed_latent += 2 * base_component\n",
    "        else:\n",
    "            disallowed_latent += (1 - v[i]) * base_component\n",
    "    #\n",
    "    return disallowed_latent\n",
    "    \n",
    "# checks if latent is allowed\n",
    "def check_latent(z):\n",
    "    if z not in disallowed_latents:\n",
    "        # check if there is at least one 0 and one 1\n",
    "        v = compute_v(z)\n",
    "        return np.count_nonzero(v == 1) >= 1 and np.count_nonzero(v == 0) >= 1\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "6d5d4c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns array of counts of j values seen in v by index i\n",
    "def compute_counts(v,j):\n",
    "    counts = []\n",
    "    cur_count = 0\n",
    "    for i in range(len(v)):\n",
    "        cur_count += int(v[i] == j)\n",
    "        counts.append(cur_count)\n",
    "    return np.array(counts)\n",
    "\n",
    "# returns sum(f_{ni} - Fo_{nj} * C_{nji}) over all (i, v[i] != 2) for given n,v\n",
    "def compute_sum_normal_exp_over_i(n,z):\n",
    "    v = compute_v(z)\n",
    "    counts = [compute_counts(v,j) for j in range(2)]\n",
    "    sum = 0\n",
    "    for i in range(NUM_FREQS):\n",
    "        if v[i] != 2:\n",
    "            count = counts[v[i]][i]\n",
    "            sum += (data[n,i] - fo_params[n,LATENTS[z],v[i]] * count) ** 2\n",
    "    return sum\n",
    "    \n",
    "\n",
    "# computes likelihoods exponents for data point n over all z\n",
    "# returns array of exponents\n",
    "def compute_likelihood_exponents(n):\n",
    "    exponents = []\n",
    "    for z in LATENTS:\n",
    "        sum = -1/(2*variance) * compute_sum_normal_exp_over_i(n,z)\n",
    "        exponents.append(sum)\n",
    "    return np.array(exponents)\n",
    "        \n",
    "\n",
    "# computes component responsibilities for data point n over all z\n",
    "# returns array of r values\n",
    "def compute_r(n):\n",
    "    exponents = compute_likelihood_exponents(n)\n",
    "    r_n = []\n",
    "    for z in LATENTS:\n",
    "        log_numerator = logsumexp([exponents[LATENTS[z]]],b=[pi_params[LATENTS[z]]])\n",
    "        log_denom = logsumexp(exponents,b=pi_params)\n",
    "        r_n.append(np.exp(log_numerator - log_denom))\n",
    "    #\n",
    "    return np.array(r_n)\n",
    "\n",
    "# computes Fo updates for data point n\n",
    "# returns array of shape (len(LATENTS),2)\n",
    "def compute_Fo_updates(n,r_values):\n",
    "    updated_Fo = []\n",
    "    for z in LATENTS:\n",
    "        Fo_pair = []\n",
    "        for j in range(2):\n",
    "            v = compute_v(z)\n",
    "            \n",
    "            i_selector = (v == j)\n",
    "            selected_counts = compute_counts(v,j)\n",
    "            sum_fs = np.dot(i_selector,data[n])\n",
    "            sum_Cs = np.dot(i_selector, selected_counts)\n",
    "            \n",
    "            Fo_pair.append(sum_fs / sum_Cs)\n",
    "        #    \n",
    "        updated_Fo.append(Fo_pair)\n",
    "    #\n",
    "    return np.array(updated_Fo)\n",
    "\n",
    "# computes and returns updated variance\n",
    "# default alpha/beta values give no prior\n",
    "def compute_variance_update(r_values,alpha=-1,beta=0):\n",
    "    total_sum_num = 0\n",
    "    total_sum_denom = 0\n",
    "    for n in range(N):\n",
    "        for z in LATENTS:\n",
    "            sum_num = compute_sum_normal_exp_over_i(n,z)\n",
    "            total_sum_num += r_values[n,LATENTS[z]] * sum_num\n",
    "            \n",
    "            v = compute_v(z)\n",
    "            total_sum_denom += r_values[n,LATENTS[z]] * np.sum(v != 2)\n",
    "        #\n",
    "    #\n",
    "    total_sum_num = 1/2 * total_sum_num + beta\n",
    "    denom = 1/2 * N * NUM_FREQS + (alpha + 1)\n",
    "    \n",
    "    return total_sum_num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "9f1e9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "N = data.shape[0]\n",
    "num_iter = 5\n",
    "var_ALPHA=1\n",
    "var_BETA=2\n",
    "\n",
    "# construct the latent space\n",
    "LATENTS = {}\n",
    "disallowed_latents = set()\n",
    "\n",
    "z_index = 0\n",
    "for z in range(1,3 ** NUM_FREQS-1):\n",
    "    if check_latent(z):\n",
    "        LATENTS[z] = z_index\n",
    "        disallowed_latents.add(compute_disallowed_z(z))\n",
    "        z_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "a69b5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter initializations\n",
    "variance = 10000000 # just testing a large number\n",
    "fo_params = np.full((N,len(LATENTS),2),np.array([5000/3,5000*2/3])) # split the 0-5000 range\n",
    "\n",
    "# compute pi initializations\n",
    "#pi_params = np.full((len(LATENTS)), 1/(len(LATENTS)))\n",
    "pi_importance_ratio = .8\n",
    "count_2s_lst = []\n",
    "num_2_counts = np.zeros(NUM_FREQS-1)\n",
    "for z in LATENTS:\n",
    "    v = compute_v(z)\n",
    "    count_2s_in_v = np.count_nonzero(v == 2)\n",
    "    count_2s_lst.append(count_2s_in_v)\n",
    "    num_2_counts[count_2s_in_v] += 1\n",
    "    \n",
    "pi_for_no_2s = 1 / np.dot(num_2_counts,np.geomspace(1, pi_importance_ratio ** (NUM_FREQS-2), num=NUM_FREQS-1))\n",
    "pi_params = pi_for_no_2s * np.power(pi_importance_ratio, np.array(count_2s_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "40351f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation Maximization\n",
    "for _ in range(num_iter):\n",
    "    # E-Step\n",
    "    r_values = np.array([compute_r(n) for n in range(N)])\n",
    "    \n",
    "    # keeping pi_params constant\n",
    "    \n",
    "    # M-Step: update Fo params\n",
    "    fo_params = np.array([compute_Fo_updates(n,r_values) for n in range(N)])\n",
    "    \n",
    "    # update variance\n",
    "    variance = compute_variance_update(r_values,var_ALPHA,var_BETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "9471e1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4645304843092684\n",
      "[[ 218.66666667  260.6       ]\n",
      " [ 260.6         438.        ]\n",
      " [ 246.          260.33333333]\n",
      " [ 260.8         492.66666667]\n",
      " [ 260.6         566.        ]\n",
      " [ 260.6         292.66666667]\n",
      " [ 260.6         586.66666667]\n",
      " [ 260.6         328.33333333]\n",
      " [ 156.          260.33333333]\n",
      " [ 260.33333333  348.        ]\n",
      " [ 260.8         698.        ]\n",
      " [  82.          260.6       ]\n",
      " [ 260.85714286 1838.        ]]\n",
      "[[0.03334406]\n",
      " [0.03462512]\n",
      " [0.03803604]\n",
      " [0.03724005]\n",
      " [0.02991524]\n",
      " [0.03336294]\n",
      " [0.03336294]\n",
      " [0.03211202]\n",
      " [0.04353785]\n",
      " [0.03398718]\n",
      " [0.03449705]\n",
      " [0.02993302]\n",
      " [0.03217424]]\n",
      "[242 222 241 222  73 240  70 241 425 243  67 414   0]\n"
     ]
    }
   ],
   "source": [
    "# check params\n",
    "indices = np.argmax(r_values,axis=1)\n",
    "fo_found = fo_params[np.arange(N),indices]\n",
    "r_chosen_responsibility = r_values[np.arange(N),indices].reshape(-1,1)\n",
    "\n",
    "print(np.sqrt(variance))\n",
    "print(fo_found)\n",
    "print(r_chosen_responsibility)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c59d3a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "54bd9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# piano key frequency formula that takes a frequency value and outputs the closest note number\n",
    "def freq_to_note_num(freq):\n",
    "    return np.rint(12 * np.log2(freq / 440) + 49).astype(np.int32)\n",
    "\n",
    "# returns note name give piano key number\n",
    "def note_num_to_name(note_num):\n",
    "    note_mapper = {\n",
    "        0: 'C',\n",
    "        1: 'C#',\n",
    "        2: 'D',\n",
    "        3: 'D#',\n",
    "        4: 'E',\n",
    "        5: 'F',\n",
    "        6: 'F#',\n",
    "        7: 'G',\n",
    "        8: 'G#',\n",
    "        9: 'A',\n",
    "        10: 'A#',\n",
    "        11: 'B',\n",
    "    }\n",
    "    \n",
    "    note = note_mapper[(note_num - 4) % 12]\n",
    "    octave_num = (note_num + 8) // 12\n",
    "    return note + str(octave_num)\n",
    "\n",
    "# takes the predicted fo values and converts them to the nearest note name\n",
    "def convert_pred_fo_to_notes(fo_found):\n",
    "    note_nums = freq_to_note_num(fo_found)\n",
    "    return [set(map(note_num_to_name,note_name_pair)) for note_name_pair in note_nums.tolist()]\n",
    "\n",
    "# computes chord accuracy\n",
    "def compute_chord_accuracy(predicted_labels):\n",
    "    error_count = 0\n",
    "    for i in range(N):\n",
    "        pred_freqs = predicted_labels[i]\n",
    "        label_set = label_strings[i]\n",
    "        \n",
    "        for fo in label_set:\n",
    "            if fo not in pred_freqs:\n",
    "                error_count += 1\n",
    "                break\n",
    "        #\n",
    "    #\n",
    "    return 1 - error_count / N\n",
    "\n",
    "# determines accuracy by individual notes\n",
    "def compute_overall_note_accuracy(predicted_labels):\n",
    "    error_count = 0\n",
    "    for i in range(N):\n",
    "        pred_freqs = predicted_labels[i]\n",
    "        label_set = label_strings[i]\n",
    "        \n",
    "        for fo in label_set:\n",
    "            if fo not in pred_freqs:\n",
    "                error_count += 1\n",
    "        #\n",
    "    #\n",
    "    return 1 - error_count / (N*2)\n",
    "\n",
    "def compute_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "02e73508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6923076923076923\n",
      "0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = convert_pred_fo_to_notes(fo_found)\n",
    "chord_accuracy = compute_chord_accuracy(predicted_labels)\n",
    "note_accuracy = compute_overall_note_accuracy(predicted_labels)\n",
    "print(chord_accuracy)\n",
    "print(note_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "ec367410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'A3', 'C4'}, {'A4', 'C4'}, {'C4', 'B3'}, {'C4', 'B4'}, {'C4', 'C#5'}, {'C4', 'D4'}, {'C4', 'D5'}, {'E4', 'C4'}, {'C4', 'D#3'}, {'C4', 'F4'}, {'F5', 'C4'}, {'E2', 'C4'}, {'C4', 'A#6'}]\n"
     ]
    }
   ],
   "source": [
    "print(convert_pred_fo_to_notes(fo_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "a09e6a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'A3', 'C4'}, {'A4', 'C4'}, {'C4', 'B3'}, {'C4', 'B4'}, {'C4', 'C5'}, {'C4', 'D4'}, {'C4', 'D5'}, {'E4', 'C4'}, {'C4', 'E5'}, {'C4', 'F4'}, {'F5', 'C4'}, {'C4', 'G4'}, {'G5', 'C4'}]\n"
     ]
    }
   ],
   "source": [
    "print(label_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dad334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beddddb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:audio_processing]",
   "language": "python",
   "name": "conda-env-audio_processing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
